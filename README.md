# üß† Calculadora Neural: Rede Neural para Opera√ß√µes Matem√°ticas

## üìã √çndice
- [Sobre o Projeto](#-sobre-o-projeto)
- [Resumo Executivo](#-resumo-executivo)
- [Prepara√ß√£o e Valida√ß√£o dos Dados](#-prepara√ß√£o-e-valida√ß√£o-dos-dados)
- [Arquitetura da Rede Neural](#-arquitetura-da-rede-neural)
- [Otimiza√ß√£o de Hiperpar√¢metros](#-otimiza√ß√£o-de-hiperpar√¢metros)
- [Implementa√ß√£o de Callbacks](#-implementa√ß√£o-de-callbacks)
- [Treinamento e Avalia√ß√£o](#-treinamento-e-avalia√ß√£o)
- [Conclus√µes e Recomenda√ß√µes](#-conclus√µes-e-recomenda√ß√µes)
- [Limita√ß√µes e Desafios](#-limita√ß√µes-e-desafios)
- [Trabalhos Futuros](#-trabalhos-futuros)
- [Como Executar](#-como-executar)
- [Uso Pr√°tico do Modelo](#-uso-pr√°tico-do-modelo)
- [Refer√™ncias](#-refer√™ncias)

## üìã Sobre o Projeto

Este projeto implementa uma rede neural profunda capaz de aprender as quatro opera√ß√µes matem√°ticas b√°sicas: adi√ß√£o, subtra√ß√£o, multiplica√ß√£o e divis√£o. Utilizando t√©cnicas avan√ßadas de deep learning e otimiza√ß√£o de hiperpar√¢metros, conseguimos criar um modelo capaz de realizar c√°lculos com diferentes n√≠veis de precis√£o dependendo da opera√ß√£o.

**Autores:**
- Wellington Costa dos Santos - 2019101307
- Janderson Sebasti√£o do Carmo Rocha - 2020101157
- Bruno Thiago Ferreira Lins - 2017102980

**Data:** 10/05/2025  
**Disciplina:** Redes Neurais 2  
**Professor:** S√©rgio Assun√ß√£o Monteiro, D.Sc.

## üìä Resumo Executivo

Nossa pesquisa implementou uma rede neural capaz de aprender as quatro opera√ß√µes matem√°ticas b√°sicas, utilizando uma arquitetura MLP com configura√ß√£o "ampulheta" (128‚Üí32‚Üí128 neur√¥nios). Principais resultados:

- **Performance Global:** MSE=0.05897, MAE=0.02049 no conjunto de teste
- **Diferen√ßas por Opera√ß√£o:** Adi√ß√£o (melhor desempenho) > Subtra√ß√£o > Multiplica√ß√£o > Divis√£o (pior desempenho)
- **Otimiza√ß√£o:** Utilizamos Keras Tuner com Hyperband para encontrar a melhor configura√ß√£o entre 90 tentativas
- **Melhor Modelo:** Combina√ß√£o de ReLU na primeira camada e SELU nas subsequentes, com regulariza√ß√£o L2 e dropout

Esta abordagem demonstra o potencial das redes neurais para modelar opera√ß√µes matem√°ticas, mas tamb√©m revela limita√ß√µes importantes para opera√ß√µes mais complexas como divis√£o.

## 1Ô∏è‚É£ Prepara√ß√£o e Valida√ß√£o dos Dados

### Dataset Sint√©tico
- Geramos um dataset contendo 4.000 exemplos (1.000 por opera√ß√£o: adi√ß√£o, subtra√ß√£o, multiplica√ß√£o e divis√£o)
- Utilizamos n√∫meros aleat√≥rios no intervalo [-10, 10], incluindo valores decimais
- Implementamos tratamento especial para evitar divis√£o por zero (valores menores que 0.01 s√£o substitu√≠dos)

```python
def gerar_dataset_operacoes(amostras_por_operacao=1000):
    """
    Gera um dataset sint√©tico para treinar opera√ß√µes matem√°ticas.
    """
    # C√°lculo do n√∫mero total de opera√ß√µes
    total_amostras = amostras_por_operacao * 4  # 4 opera√ß√µes: +, -, *, /
    
    # Gera√ß√£o de n√∫meros aleat√≥rios entre -10 e 10
    operando_1 = np.random.uniform(-10, 10, total_amostras)
    operando_2 = np.random.uniform(-10, 10, total_amostras)
    
    # Preven√ß√£o de divis√£o por zero: substitui valores pr√≥ximos de zero
    indice_inicio_divisao = amostras_por_operacao * 3
    operando_2[indice_inicio_divisao:][np.abs(operando_2[indice_inicio_divisao:]) < 0.01] = 0.01
    
    # Cria√ß√£o dos c√≥digos de opera√ß√£o (0: soma, 1: subtra√ß√£o, 2: multiplica√ß√£o, 3: divis√£o)
    codigos_operacao = np.concatenate([
        np.zeros(amostras_por_operacao),          # Adi√ß√£o (0)
        np.ones(amostras_por_operacao),           # Subtra√ß√£o (1)
        np.full(amostras_por_operacao, 2),        # Multiplica√ß√£o (2)
        np.full(amostras_por_operacao, 3)         # Divis√£o (3)
    ])
    
    # Combina√ß√£o dos operandos e c√≥digos de opera√ß√£o como entrada (X)
    X = np.column_stack((operando_1, operando_2, codigos_operacao))
    
    # C√°lculo dos resultados esperados (y)
    resultados = np.concatenate([
        # Adi√ß√£o: a + b
        operando_1[:amostras_por_operacao] + operando_2[:amostras_por_operacao],
        
        # Subtra√ß√£o: a - b
        operando_1[amostras_por_operacao:2*amostras_por_operacao] - 
        operando_2[amostras_por_operacao:2*amostras_por_operacao],
        
        # Multiplica√ß√£o: a * b
        operando_1[2*amostras_por_operacao:3*amostras_por_operacao] * 
        operando_2[2*amostras_por_operacao:3*amostras_por_operacao],
        
        # Divis√£o: a / b
        operando_1[3*amostras_por_operacao:] / operando_2[3*amostras_por_operacao:]
    ])
    
    return X, resultados
```

### Divis√£o dos Dados
- **Treino (60%):** 2.400 exemplos para aprendizado do modelo
- **Valida√ß√£o (20%):** 800 exemplos para otimiza√ß√£o de hiperpar√¢metros
- **Teste (20%):** 800 exemplos para avalia√ß√£o final

```python
# Divis√£o dos dados em conjuntos de treino (60%), valida√ß√£o (20%) e teste (20%)
X_temp, X_teste, y_temp, y_teste = train_test_split(
    X_completo, y_completo, test_size=0.2, random_state=SEED
)
X_treino, X_validacao, y_treino, y_validacao = train_test_split(
    X_temp, y_temp, test_size=0.25, random_state=SEED
)
```

### Justificativa da Divis√£o
Esta propor√ß√£o foi escolhida para:
1. Garantir dados suficientes para treinamento adequado
2. Manter um conjunto de valida√ß√£o robusto para otimiza√ß√£o de hiperpar√¢metros
3. Reservar uma quantidade representativa para teste independente

### Pr√©-processamento
- **Normaliza√ß√£o:** Utilizamos MinMaxScaler com range=(-1, 1) para operandos e resultados
- **Codifica√ß√£o:** Transformamos os c√≥digos de opera√ß√£o (0-3) em vetores one-hot
- Essa normaliza√ß√£o √© crucial para equilibrar a influ√™ncia dos valores e melhorar a converg√™ncia

```python
# Inicializa√ß√£o dos transformadores para pr√©-processamento
escala_entrada = MinMaxScaler(feature_range=(-1, 1))  # Normaliza n√∫meros para [-1, 1]
escala_saida = MinMaxScaler(feature_range=(-1, 1))    # Normaliza resultados para [-1, 1]
codificador_operacoes = OneHotEncoder(sparse_output=False)  # Transforma c√≥digos em vetores one-hot

def transformar_dados(X, y, ajustar_transformadores=False):
    """
    Normaliza os valores num√©ricos e codifica as opera√ß√µes.
    """
    # Separa√ß√£o dos operandos e dos c√≥digos de opera√ß√£o
    numeros = X[:, :2]                 # Primeiras duas colunas (operandos)
    operacoes = X[:, 2].reshape(-1, 1)  # Terceira coluna (c√≥digos de opera√ß√£o)
    
    # Normaliza√ß√£o e codifica√ß√£o
    if ajustar_transformadores:
        # Primeira vez: ajusta os transformadores aos dados
        numeros_norm = escala_entrada.fit_transform(numeros)
        y_norm = escala_saida.fit_transform(y.reshape(-1, 1)).flatten()
        operacoes_codificadas = codificador_operacoes.fit_transform(operacoes)
    else:
        # Usa transformadores j√° ajustados
        numeros_norm = escala_entrada.transform(numeros)
        y_norm = escala_saida.transform(y.reshape(-1, 1)).flatten()
        operacoes_codificadas = codificador_operacoes.transform(operacoes)
    
    # Combina√ß√£o dos dados processados
    return np.hstack([numeros_norm, operacoes_codificadas]), y_norm
```

## 2Ô∏è‚É£ Arquitetura da Rede Neural

### Estrutura Inicial
- Implementamos uma MLP com m√∫ltiplas camadas densas 
- Exploramos diferentes configura√ß√µes com 2-4 camadas ocultas
- Finalizamos com uma camada de sa√≠da com 1 neur√¥nio (resultado da opera√ß√£o)

```python
def construir_modelo(hp):
    """
    Fun√ß√£o para construir o modelo com hiperpar√¢metros otimiz√°veis.
    """
    # Inicializa√ß√£o do modelo sequencial
    modelo = tf.keras.Sequential()
    
    # Camada de entrada com forma definida pelos dados processados
    modelo.add(tf.keras.layers.Input(shape=(X_treino_norm.shape[1],)))
    
    # N√∫mero de camadas ocultas a ser otimizado (entre 2 e 4)
    num_camadas = hp.Int("num_camadas", min_value=2, max_value=4, step=1)
    
    # Adi√ß√£o das camadas ocultas com hiperpar√¢metros otimiz√°veis
    for i in range(num_camadas):
        # N√∫mero de neur√¥nios na camada
        unidades = hp.Int(f"unidades_{i}", min_value=32, max_value=128, step=32)
        
        # Regulariza√ß√£o L2 para preven√ß√£o de overfitting
        regularizador = tf.keras.regularizers.l2(
            hp.Choice(f"l2_{i}", values=[0.001, 0.0001])
        )
        
        # Adi√ß√£o da camada densa
        modelo.add(tf.keras.layers.Dense(
            units=unidades,
            kernel_regularizer=regularizador
        ))
        
        # Fun√ß√£o de ativa√ß√£o
        ativacao = hp.Choice(
            f"ativacao_{i}", 
            values=["relu", "tanh", "selu", "leaky_relu"]
        )
        
        if ativacao == "leaky_relu":
            modelo.add(tf.keras.layers.LeakyReLU())
        else:
            modelo.add(tf.keras.layers.Activation(ativacao))
        
        # Dropout opcional para regulariza√ß√£o adicional
        if hp.Boolean(f"usar_dropout_{i}"):
            taxa_dropout = hp.Float(f"dropout_{i}", min_value=0.1, max_value=0.4, step=0.1)
            modelo.add(tf.keras.layers.Dropout(rate=taxa_dropout))
    
    # Camada de sa√≠da (uma √∫nica unidade para o resultado da opera√ß√£o)
    modelo.add(tf.keras.layers.Dense(1))
    
    # ... [continua√ß√£o do c√≥digo de compila√ß√£o]
    
    return modelo
```

### Diagrama da Arquitetura Final

```
Entrada (6 unidades: 2 operandos + 4 one-hot)
    ‚Üì
Camada Densa (128 unidades, ReLU, L2=0.0001)
    ‚Üì
Dropout (30%)
    ‚Üì
Camada Densa (32 unidades, SELU, L2=0.001)
    ‚Üì
Camada Densa (128 unidades, SELU, L2=0.001)
    ‚Üì
Dropout (10%)
    ‚Üì
Camada de Sa√≠da (1 unidade)
```

### T√©cnicas de Regulariza√ß√£o
- **Dropout:** Aplicado em taxas vari√°veis (0.1-0.4) para prevenir overfitting
- **Regulariza√ß√£o L2:** Implementada com coeficientes 0.001 e 0.0001
- A combina√ß√£o dessas t√©cnicas provou ser eficaz para melhorar a generaliza√ß√£o

```python
# Trecho destacando a implementa√ß√£o de regulariza√ß√£o
regularizador = tf.keras.regularizers.l2(
    hp.Choice(f"l2_{i}", values=[0.001, 0.0001])
)

# Adi√ß√£o da camada densa com regulariza√ß√£o
modelo.add(tf.keras.layers.Dense(
    units=unidades,
    kernel_regularizer=regularizador
))

# Implementa√ß√£o de Dropout
if hp.Boolean(f"usar_dropout_{i}"):
    taxa_dropout = hp.Float(f"dropout_{i}", min_value=0.1, max_value=0.4, step=0.1)
    modelo.add(tf.keras.layers.Dropout(rate=taxa_dropout))
```

### Compara√ß√£o de Fun√ß√µes de Ativa√ß√£o
Testamos diferentes fun√ß√µes de ativa√ß√£o:
- **ReLU:** Boa performance, especialmente nas primeiras camadas
- **LeakyReLU:** Desempenho similar ao ReLU em nossos testes
- **Tanh:** N√£o mostrou vantagens significativas para este problema
- **SELU:** Apresentou excelentes resultados nas camadas intermedi√°rias e finais

```python
# C√≥digo que implementa a sele√ß√£o de diferentes fun√ß√µes de ativa√ß√£o
ativacao = hp.Choice(
    f"ativacao_{i}", 
    values=["relu", "tanh", "selu", "leaky_relu"]
)

if ativacao == "leaky_relu":
    modelo.add(tf.keras.layers.LeakyReLU())
else:
    modelo.add(tf.keras.layers.Activation(ativacao))
```

A combina√ß√£o vencedora utilizou ReLU na primeira camada e SELU nas subsequentes.

## 3Ô∏è‚É£ Otimiza√ß√£o de Hiperpar√¢metros

### Metodologia
Utilizamos Keras Tuner com o algoritmo Hyperband para busca eficiente, explorando:
- **N√∫mero de neur√¥nios:** 32, 64, 96 ou 128 por camada
- **Taxa de aprendizado:** Range de 1e-4 a 1e-2 (escala logar√≠tmica)
- **Coeficientes de regulariza√ß√£o L2:** 0.001 ou 0.0001
- **Otimizadores:** Adam, RMSprop e SGD com momentum

```python
# Inicializa√ß√£o do otimizador de hiperpar√¢metros (Hyperband)
otimizador_hiperparametros = kt.Hyperband(
    construir_modelo,
    objective="val_mae",           # Objetivo: minimizar o erro absoluto m√©dio na valida√ß√£o
    max_epochs=30,                 # N√∫mero m√°ximo de √©pocas para cada trial
    factor=3,                      # Fator de redu√ß√£o para o Hyperband
    directory="diretorio_tuning",  # Diret√≥rio para armazenar resultados
    project_name="mlp_matematica"  # Nome do projeto
)

# Sele√ß√£o do otimizador como um hiperpar√¢metro
otimizador_nome = hp.Choice(
    "otimizador", 
    values=["adam", "rmsprop", "sgd"]
)

# Taxa de aprendizado otimiz√°vel
taxa_aprendizado = hp.Float(
    "taxa_aprendizado", 
    min_value=1e-4, 
    max_value=1e-2, 
    sampling="log"
)

# Cria√ß√£o do otimizador escolhido com a taxa de aprendizado
otimizadores = {
    "adam": tf.keras.optimizers.Adam(learning_rate=taxa_aprendizado),
    "rmsprop": tf.keras.optimizers.RMSprop(learning_rate=taxa_aprendizado),
    "sgd": tf.keras.optimizers.SGD(learning_rate=taxa_aprendizado, momentum=0.9)
}
otimizador = otimizadores[otimizador_nome]
```

### Resultados da Otimiza√ß√£o
Ap√≥s 90 trials (8m12s de processamento):
- **Melhor configura√ß√£o (Trial #87):** MAE de valida√ß√£o = 0.01958
- **√öltimo trial (#90):** MAE de valida√ß√£o = 0.0805 (significativamente pior)
- **Arquitetura vencedora:** 3 camadas com estrutura "ampulheta" (128‚Üí32‚Üí128)

```
Trial 90 Complete [00h 00m 13s]
val_mae: 0.08050110936164856
Best val_mae So Far: 0.01958031952381134
Total elapsed time: 00h 08m 12s
```

### Curva de Converg√™ncia

A figura abaixo mostra a evolu√ß√£o do MAE de valida√ß√£o para os diferentes trials ao longo do processo de otimiza√ß√£o:

```
    MAE
0.08 |    *                             *
     |        *             *              
     |  *         *     *       *          
0.04 |     *  *     *       *             
     |            *   *  *                
     |                      *   *         
0.02 |                          *         
     +--------------------------------
         0   20   40   60   80   Trial#
```

### Compara√ß√£o de Otimizadores
- **Adam:** Mostrou converg√™ncia mais r√°pida e est√°vel (escolhido com taxa de 0.001815)
- **RMSprop:** Performance similar ao Adam, mas ligeiramente menos est√°vel
- **SGD com momentum:** Converg√™ncia mais lenta, mas capaz de encontrar bons m√≠nimos

```python
# Compila√ß√£o do modelo com o otimizador escolhido
modelo.compile(
    optimizer=otimizador,
    loss='mse',                # Erro quadr√°tico m√©dio para regress√£o
    metrics=['mae']            # Erro absoluto m√©dio como m√©trica adicional
)
```

## 4Ô∏è‚É£ Implementa√ß√£o de Callbacks

### Callbacks Utilizados
- **Early Stopping:** Interrompe o treinamento ap√≥s 5 √©pocas sem melhoria no MAE de valida√ß√£o
- **ModelCheckpoint:** Salva apenas o melhor modelo baseado no MAE de valida√ß√£o
- **TensorBoard:** Registra m√©tricas para visualiza√ß√£o gr√°fica do treinamento

```python
otimizador_hiperparametros.search(
    X_treino_norm, y_treino_norm,
    validation_data=(X_validacao_norm, y_validacao_norm),
    callbacks=[
        # Early stopping para interromper trials sem progresso
        tf.keras.callbacks.EarlyStopping(
            patience=5,                   # N√∫mero de √©pocas sem melhoria
            restore_best_weights=True     # Restaura os melhores pesos
        ),
        
        # Checkpoint para salvar o melhor modelo
        tf.keras.callbacks.ModelCheckpoint(
            "melhor_modelo.keras",
            save_best_only=True           # Salva apenas quando h√° melhoria
        ),
        
        # TensorBoard para visualiza√ß√£o do treinamento
        tf.keras.callbacks.TensorBoard(log_dir=log_dir),
        
        # Outros callbacks...
    ],
    verbose=2  # N√≠vel de detalhamento das mensagens
)
```

### Callback Personalizado
Implementamos um LimitadorDeTrials que:
- Controla o n√∫mero m√°ximo de trials durante a otimiza√ß√£o (limite: 59)
- Interrompe trials que excedem este limite para otimizar o tempo total

```python
# Callback personalizado para limitar o n√∫mero de trials
class LimitadorDeTrials(tf.keras.callbacks.Callback):
    """
    Callback para limitar o n√∫mero de trials durante a busca de hiperpar√¢metros.
    """
    def __init__(self, max_trials=59):
        super().__init__()
        self.max_trials = max_trials
        self.trial_atual = 0
    
    def on_train_begin(self, logs=None):
        self.trial_atual += 1
        if self.trial_atual > self.max_trials:
            print(f"\n‚õî Atingido o limite de {self.max_trials} trials. Interrompendo busca.")
            self.model.stop_training = True
```

Adicionalmente, utilizamos um LambdaCallback para exibir m√©tricas em tempo real:
```python
# Callback personalizado para mostrar progresso em tempo real
tf.keras.callbacks.LambdaCallback(
    on_epoch_end=lambda epoca, logs: print(
        f'√âpoca {epoca+1} - MAE: {logs["mae"]:.4f}, Val MAE: {logs["val_mae"]:.4f}'
    )
)
```

## 5Ô∏è‚É£ Treinamento e Avalia√ß√£o

### Resultados do Treinamento
- **M√©tricas no conjunto de teste:** MSE=0.05897, MAE=0.02049
- **Total de par√¢metros:** 9.377 (todos trein√°veis)

```python
# Avalia√ß√£o no conjunto de teste
avaliacao_final = melhor_modelo.evaluate(X_teste_norm, y_teste_norm)
print("\n‚úÖ Avalia√ß√£o final (MSE, MAE):", avaliacao_final)
# Resultado: [0.058975763618946075, 0.02049693651497364]
```

### Resumo do Modelo Final

| Caracter√≠stica | Valor |
|----------------|-------|
| Camadas | 9 |
| Par√¢metros Trein√°veis | 9,377 |
| Otimizador | Adam (lr=0.001815) |
| Fun√ß√£o de Perda | MSE |

### Desempenho por Opera√ß√£o

| Opera√ß√£o | Erro M√©dio | Erro Mediano | Erro M√°ximo | Acertos (‚â§5% erro) |
|----------|------------|--------------|-------------|----------------|
| Adi√ß√£o | 0.634 | 0.327 | 9.611 | 4/5 (80%) |
| Subtra√ß√£o | 0.946 | 0.738 | 10.407 | 1/5 (20%) |
| Multiplica√ß√£o | 2.944 | 2.048 | 18.944 | 2/5 (40%) |
| Divis√£o | 7.408 | 1.064 | 930.638 | 0/5 (0%) |

### Gr√°fico de Compara√ß√£o de Desempenho por Opera√ß√£o

```
Erro M√©dio por Opera√ß√£o:
    Erro
 8.0 |                               ‚ñà
     |                               ‚ñà
 6.0 |                               ‚ñà
     |                               ‚ñà
 4.0 |                               ‚ñà
     |                      ‚ñà        ‚ñà
 2.0 |                      ‚ñà        ‚ñà
     |           ‚ñà          ‚ñà        ‚ñà
 0.0 |     ‚ñà     ‚ñà          ‚ñà        ‚ñà
     +-------------------------------------
           Adi√ß√£o Subtra√ß√£o Multi  Divis√£o
```

### An√°lise de Casos Espec√≠ficos
Exemplos representativos do conjunto de teste:

**Adi√ß√£o (bom desempenho):**
```
-3.58 + -5.19 = -8.7784 (Predito: -8.9009, Erro: 0.1225)
```

**Subtra√ß√£o (desempenho vari√°vel):**
```
-9.90 - 9.67 = -19.5680 (Predito: -26.3897, Erro: 6.8216)
```

**Multiplica√ß√£o (desafios em valores maiores):**
```
-9.00 * -6.32 = 56.8851 (Predito: 54.2390, Erro: 2.6461)
```

**Divis√£o (problemas significativos):**
```
-2.11 / -0.89 = 2.3601 (Predito: 0.0550, Erro: 2.3051)
```

### An√°lise de Overfitting/Underfitting
- N√£o observamos overfitting significativo gra√ßas √†s t√©cnicas de regulariza√ß√£o
- A diverg√™ncia entre erros por opera√ß√£o sugere que um √∫nico modelo pode n√£o ser ideal para todas as opera√ß√µes
- Os resultados indicam que a rede generaliza bem para adi√ß√£o, mas tem dificuldades crescentes com opera√ß√µes mais complexas

## üîç Conclus√µes e Recomenda√ß√µes

### Principais Insights
1. Hierarquia clara de dificuldade: Adi√ß√£o < Subtra√ß√£o < Multiplica√ß√£o < Divis√£o
2. A estrutura "ampulheta" (128‚Üí32‚Üí128) mostrou-se eficiente para capturar padr√µes matem√°ticos
3. A combina√ß√£o ReLU + SELU superou configura√ß√µes homog√™neas de ativa√ß√£o

### Melhorias Propostas
1. **Modelos Especializados:** Treinar redes separadas para cada opera√ß√£o
2. **Pr√©-processamento Adaptativo:** Diferentes estrat√©gias de normaliza√ß√£o por opera√ß√£o
3. **Dataset Expandido:** Maior cobertura de casos extremos, especialmente para divis√£o
4. **Arquiteturas Alternativas:** Explorar redes mais profundas para opera√ß√µes complexas

## üöß Limita√ß√µes e Desafios

Durante o desenvolvimento do projeto, enfrentamos diversos desafios e identificamos limita√ß√µes importantes:

1. **Precis√£o da Divis√£o:** O modelo apresentou dificuldades significativas com a opera√ß√£o de divis√£o, especialmente com denominadores pr√≥ximos a zero, refletindo a natureza matematicamente mais complexa desta opera√ß√£o.

2. **Generaliza√ß√£o para Valores Extremos:** Os maiores erros ocorreram em casos com valores nos extremos do intervalo [-10, 10], indicando a necessidade de melhor cobertura de exemplos nessas regi√µes.

3. **Otimiza√ß√£o Computacional:** A busca de hiperpar√¢metros demandou recursos significativos (8m12s para 90 trials), indicando a necessidade de otimiza√ß√£o para uso em ambientes com recursos limitados.

4. **Modelo √önico vs. Especializado:** Uma √∫nica rede para todas as opera√ß√µes apresenta vantagens de implementa√ß√£o, mas compromete a precis√£o, especialmente nas opera√ß√µes mais complexas.

5. **Range Limitado:** Os resultados sugerem que o modelo atual pode n√£o generalizar bem para valores fora do intervalo de treinamento [-10, 10].

## üî≠ Trabalhos Futuros

Com base nos resultados obtidos e nas limita√ß√µes identificadas, planejamos as seguintes dire√ß√µes para pesquisas futuras:

1. **Arquiteturas Especializadas:** Desenvolver e comparar modelos dedicados para cada opera√ß√£o matem√°tica, potencialmente aumentando a complexidade para multiplica√ß√£o e divis√£o.

2. **Explora√ß√£o de T√©cnicas de Aten√ß√£o:** Implementar mecanismos de aten√ß√£o para melhorar a capacidade do modelo de focar em diferentes aspectos dos operandos dependendo da opera√ß√£o.

3. **Expans√£o para Opera√ß√µes Mais Complexas:** Treinar o modelo para realizar opera√ß√µes como exponencia√ß√£o, raiz quadrada e opera√ß√µes com m√∫ltiplos operandos.

4. **Implementa√ß√£o em Dispositivos de Baixo Recurso:** Otimizar o modelo para execu√ß√£o em dispositivos m√≥veis ou embarcados, explorando t√©cnicas de quantiza√ß√£o e compress√£o.

5. **Abordagem H√≠brida Neural-Simb√≥lica:** Combinar a rede neural com um sistema de regras para melhorar o desempenho em casos especiais (como divis√£o por n√∫meros pr√≥ximos a zero).

## üöÄ Como Executar

```bash
# Instala√ß√£o das depend√™ncias
pip install tensorflow numpy matplotlib sklearn keras-tuner

# Executar o c√≥digo principal
python final.py

# Visualizar logs no TensorBoard
tensorboard --logdir=logs_tensorboard/
```

## üîå Uso Pr√°tico do Modelo

Ap√≥s o treinamento, voc√™ pode utilizar o modelo para realizar opera√ß√µes matem√°ticas conforme o exemplo abaixo:

```python
# Carregar o modelo treinado
from tensorflow import keras
import numpy as np
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder

# Carregar modelo e transformadores
modelo = keras.models.load_model("melhor_modelo.keras")
escala_entrada = MinMaxScaler(feature_range=(-1, 1))
escala_saida = MinMaxScaler(feature_range=(-1, 1))
codificador_operacoes = OneHotEncoder(sparse_output=False)

# Carregar os estados dos transformadores (c√≥digo simplificado)
# Na pr√°tica, voc√™ precisaria salvar e carregar estes estados

def calcular_operacao(a, b, operacao):
    """
    Realiza o c√°lculo usando o modelo neural.
    
    Par√¢metros:
        a, b: Operandos (valores entre -10 e 10)
        operacao: C√≥digo da opera√ß√£o (0: +, 1: -, 2: *, 3: /)
        
    Retorna:
        Resultado da opera√ß√£o
    """
    # Pr√©-processar operandos
    numeros = np.array([[a, b]])
    numeros_norm = escala_entrada.transform(numeros)
    
    # Pr√©-processar c√≥digo da opera√ß√£o
    operacao_reshape = np.array([[operacao]])
    operacao_cod = codificador_operacoes.transform(operacao_reshape)
    
    # Combinar para entrada final
    entrada_processada = np.hstack([numeros_norm, operacao_cod])
    
    # Fazer previs√£o
    resultado_norm = modelo.predict(entrada_processada, verbose=0)[0, 0]
    resultado = escala_saida.inverse_transform([[resultado_norm]])[0, 0]
    
    return resultado

# Exemplo de uso
a, b = 5.7, -3.2
print(f"{a} + {b} = {calcular_operacao(a, b, 0)}")
print(f"{a} - {b} = {calcular_operacao(a, b, 1)}")
print(f"{a} * {b} = {calcular_operacao(a, b, 2)}")
print(f"{a} / {b} = {calcular_operacao(a, b, 3)}")
```