# üß† Calculadora Neural: Rede Neural para Opera√ß√µes Matem√°ticas

## üìã Sobre o Projeto

Este projeto implementa uma rede neural profunda capaz de aprender as quatro opera√ß√µes matem√°ticas b√°sicas: adi√ß√£o, subtra√ß√£o, multiplica√ß√£o e divis√£o. Utilizando t√©cnicas avan√ßadas de deep learning e otimiza√ß√£o de hiperpar√¢metros, conseguimos criar um modelo capaz de realizar c√°lculos com diferentes n√≠veis de precis√£o dependendo da opera√ß√£o.

**Autores:**
- Wellington Costa dos Santos - 2019101307
- Janderson Sebasti√£o do Carmo Rocha - 2020101157
- Bruno Thiago Ferreira Lins - 2017102980

**Data:** 10/05/2025  
**Disciplina:** Redes Neurais 2  
**Professor:** S√©rgio Assun√ß√£o Monteiro, D.Sc.

## üîç Resumo do Modelo

| Caracter√≠stica | Valor |
|----------------|-------|
| Camadas | 9 |
| Par√¢metros Trein√°veis | 9,377 |
| Otimizador | Adam |
| Fun√ß√£o de Perda | MSE |

### Insights T√©cnicos
- **Fun√ß√µes de Ativa√ß√£o:** ReLU, SELU
- **Total de Camadas Densas:** 4
- **M√©trica de Avalia√ß√£o:** MAE (Erro Absoluto M√©dio)
- **Arquitetura:** MLP com entrada de 2 valores + codifica√ß√£o one-hot da opera√ß√£o
- **Fun√ß√µes n√£o utilizadas:** tanh, leaky_relu

## üìä Desempenho por Opera√ß√£o

### Erro M√©dio por Opera√ß√£o (%)
- **Adi√ß√£o:** 5.9%
- **Subtra√ß√£o:** 41.0%
- **Multiplica√ß√£o:** 31.4%
- **Divis√£o:** 155.6%

### Acertos por Opera√ß√£o (‚â§ 5% erro)
- **Adi√ß√£o:** 4/5 testes (80%)
- **Subtra√ß√£o:** 1/5 testes (20%)
- **Multiplica√ß√£o:** 2/5 testes (40%)
- **Divis√£o:** 0/5 testes (0%)

## üíª Implementa√ß√£o

O projeto utiliza TensorFlow e Keras para implementa√ß√£o da rede neural, juntamente com o Keras Tuner para otimiza√ß√£o de hiperpar√¢metros.

### Principais Componentes:
1. **Gera√ß√£o de Dados:** Dataset sint√©tico com n√∫meros aleat√≥rios para as quatro opera√ß√µes
2. **Pr√©-processamento:** Normaliza√ß√£o dos valores e codifica√ß√£o one-hot das opera√ß√µes
3. **Arquitetura do Modelo:** Rede neural profunda com camadas densas e regulariza√ß√£o
4. **Otimiza√ß√£o de Hiperpar√¢metros:** Utilizando Hyperband para encontrar a melhor configura√ß√£o
5. **Avalia√ß√£o:** Testes com exemplos reais e an√°lise detalhada de erros

### Melhores Hiperpar√¢metros Encontrados:
- **N√∫mero de camadas:** 3
- **Otimizador:** Adam
- **Taxa de aprendizado:** 0.001815
- **Camada 1:** 128 neur√¥nios, ReLU, L2=0.0001, Dropout=0.3
- **Camada 2:** 32 neur√¥nios, SELU, L2=0.001, sem Dropout
- **Camada 3:** 128 neur√¥nios, SELU, L2=0.001, Dropout=0.1

## üìà Resultados e Conclus√µes

A rede neural conseguiu aprender com maior facilidade opera√ß√µes de adi√ß√£o, enquanto teve dificuldades significativas com divis√£o. Os resultados mostram que:

- O modelo √© excelente para adi√ß√£o (80% de acertos com erro ‚â§ 5%)
- Razo√°vel para multiplica√ß√£o (40% de acertos com erro ‚â§ 5%)
- Limitado para subtra√ß√£o (20% de acertos com erro ‚â§ 5%)
- Inadequado para divis√£o (0% de acertos com erro ‚â§ 5%)

O erro m√©dio absoluto (MAE) final no conjunto de teste foi de aproximadamente 0.0205, indicando um bom desempenho geral, mas com varia√ß√µes significativas entre as opera√ß√µes.

## üîÆ Pr√≥ximos Passos

Com base nos resultados obtidos, sugerimos as seguintes melhorias:

1. **Modelos Especializados:** Treinar redes separadas para cada opera√ß√£o
2. **Amplia√ß√£o do Dataset:** Aumentar a quantidade e diversidade dos dados de treinamento
3. **Arquiteturas Alternativas:** Testar RNNs ou Transformers para capturar padr√µes sequenciais
4. **Processamento Adicional:** Melhorar a normaliza√ß√£o de dados para opera√ß√µes de divis√£o
5. **T√©cnicas de Ensemble:** Combinar m√∫ltiplos modelos para melhorar a precis√£o geral

## üöÄ Como Executar

```bash
# Instala√ß√£o das depend√™ncias
pip install tensorflow numpy matplotlib sklearn keras-tuner

# Executar o c√≥digo principal
final.py
```

## üìö Refer√™ncias

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.
- TensorFlow Documentation: https://www.tensorflow.org/
- Keras Tuner: https://keras.io/keras_tuner/
- Chollet, F. (2021). Deep Learning with Python. Manning Publications.