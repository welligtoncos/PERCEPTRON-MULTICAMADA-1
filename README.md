# üß† Calculadora Neural: Rede Neural para Opera√ß√µes Matem√°ticas

## üìã Sobre o Projeto

Este projeto implementa uma rede neural profunda capaz de aprender as quatro opera√ß√µes matem√°ticas b√°sicas: adi√ß√£o, subtra√ß√£o, multiplica√ß√£o e divis√£o. Utilizando t√©cnicas avan√ßadas de deep learning e otimiza√ß√£o de hiperpar√¢metros, conseguimos criar um modelo capaz de realizar c√°lculos com diferentes n√≠veis de precis√£o dependendo da opera√ß√£o.

**Autores:**
- Wellington Costa dos Santos - 2019101307
- Janderson Sebasti√£o do Carmo Rocha - 2020101157
- Bruno Thiago Ferreira Lins - 2017102980

**Data:** 10/05/2025  
**Disciplina:** Redes Neurais 2  
**Professor:** S√©rgio Assun√ß√£o Monteiro, D.Sc.

## 1Ô∏è‚É£ Prepara√ß√£o e Valida√ß√£o dos Dados

### Dataset Sint√©tico
- Geramos um dataset contendo 4.000 exemplos (1.000 por opera√ß√£o: adi√ß√£o, subtra√ß√£o, multiplica√ß√£o e divis√£o)
- Utilizamos n√∫meros aleat√≥rios no intervalo [-10, 10], incluindo valores decimais
- Implementamos tratamento especial para evitar divis√£o por zero (valores menores que 0.01 s√£o substitu√≠dos)

### Divis√£o dos Dados
- **Treino (60%):** 2.400 exemplos para aprendizado do modelo
- **Valida√ß√£o (20%):** 800 exemplos para otimiza√ß√£o de hiperpar√¢metros
- **Teste (20%):** 800 exemplos para avalia√ß√£o final

### Justificativa da Divis√£o
Esta propor√ß√£o foi escolhida para:
1. Garantir dados suficientes para treinamento adequado
2. Manter um conjunto de valida√ß√£o robusto para otimiza√ß√£o de hiperpar√¢metros
3. Reservar uma quantidade representativa para teste independente

### Pr√©-processamento
- **Normaliza√ß√£o:** Utilizamos MinMaxScaler com range=(-1, 1) para operandos e resultados
- **Codifica√ß√£o:** Transformamos os c√≥digos de opera√ß√£o (0-3) em vetores one-hot
- Essa normaliza√ß√£o √© crucial para equilibrar a influ√™ncia dos valores e melhorar a converg√™ncia

## 2Ô∏è‚É£ Arquitetura da Rede Neural

### Estrutura Inicial
- Implementamos uma MLP com m√∫ltiplas camadas densas 
- Exploramos diferentes configura√ß√µes com 2-4 camadas ocultas
- Finalizamos com uma camada de sa√≠da com 1 neur√¥nio (resultado da opera√ß√£o)

### T√©cnicas de Regulariza√ß√£o
- **Dropout:** Aplicado em taxas vari√°veis (0.1-0.4) para prevenir overfitting
- **Regulariza√ß√£o L2:** Implementada com coeficientes 0.001 e 0.0001
- A combina√ß√£o dessas t√©cnicas provou ser eficaz para melhorar a generaliza√ß√£o

### Compara√ß√£o de Fun√ß√µes de Ativa√ß√£o
Testamos diferentes fun√ß√µes de ativa√ß√£o:
- **ReLU:** Boa performance, especialmente nas primeiras camadas
- **LeakyReLU:** Desempenho similar ao ReLU em nossos testes
- **Tanh:** N√£o mostrou vantagens significativas para este problema
- **SELU:** Apresentou excelentes resultados nas camadas intermedi√°rias e finais

A combina√ß√£o vencedora utilizou ReLU na primeira camada e SELU nas subsequentes.

## 3Ô∏è‚É£ Otimiza√ß√£o de Hiperpar√¢metros

### Metodologia
Utilizamos Keras Tuner com o algoritmo Hyperband para busca eficiente, explorando:
- **N√∫mero de neur√¥nios:** 32, 64, 96 ou 128 por camada
- **Taxa de aprendizado:** Range de 1e-4 a 1e-2 (escala logar√≠tmica)
- **Coeficientes de regulariza√ß√£o L2:** 0.001 ou 0.0001
- **Otimizadores:** Adam, RMSprop e SGD com momentum

### Resultados da Otimiza√ß√£o
Ap√≥s 90 trials (8m12s de processamento):
- **Melhor configura√ß√£o (Trial #87):** MAE de valida√ß√£o = 0.01958
- **√öltimo trial (#90):** MAE de valida√ß√£o = 0.0805 (significativamente pior)
- **Arquitetura vencedora:** 3 camadas com estrutura "ampulheta" (128‚Üí32‚Üí128)

### Compara√ß√£o de Otimizadores
- **Adam:** Mostrou converg√™ncia mais r√°pida e est√°vel (escolhido com taxa de 0.001815)
- **RMSprop:** Performance similar ao Adam, mas ligeiramente menos est√°vel
- **SGD com momentum:** Converg√™ncia mais lenta, mas capaz de encontrar bons m√≠nimos

## 4Ô∏è‚É£ Implementa√ß√£o de Callbacks

### Callbacks Utilizados
- **Early Stopping:** Interrompe o treinamento ap√≥s 5 √©pocas sem melhoria no MAE de valida√ß√£o
- **ModelCheckpoint:** Salva apenas o melhor modelo baseado no MAE de valida√ß√£o
- **TensorBoard:** Registra m√©tricas para visualiza√ß√£o gr√°fica do treinamento

### Callback Personalizado
Implementamos um LimitadorDeTrials que:
- Controla o n√∫mero m√°ximo de trials durante a otimiza√ß√£o (limite: 59)
- Interrompe trials que excedem este limite para otimizar o tempo total

Adicionalmente, utilizamos um LambdaCallback para exibir m√©tricas em tempo real:
```python
tf.keras.callbacks.LambdaCallback(
    on_epoch_end=lambda epoca, logs: print(
        f'√âpoca {epoca+1} - MAE: {logs["mae"]:.4f}, Val MAE: {logs["val_mae"]:.4f}'
    )
)
```

## 5Ô∏è‚É£ Treinamento e Avalia√ß√£o

### Resultados do Treinamento
- **M√©tricas no conjunto de teste:** MSE=0.05897, MAE=0.02049
- **Total de par√¢metros:** 9.377 (todos trein√°veis)

### Resumo do Modelo Final

| Caracter√≠stica | Valor |
|----------------|-------|
| Camadas | 9 |
| Par√¢metros Trein√°veis | 9,377 |
| Otimizador | Adam (lr=0.001815) |
| Fun√ß√£o de Perda | MSE |

### Desempenho por Opera√ß√£o

| Opera√ß√£o | Erro M√©dio | Erro Mediano | Erro M√°ximo | Acertos (‚â§5% erro) |
|----------|------------|--------------|-------------|----------------|
| Adi√ß√£o | 0.634 | 0.327 | 9.611 | 4/5 (80%) |
| Subtra√ß√£o | 0.946 | 0.738 | 10.407 | 1/5 (20%) |
| Multiplica√ß√£o | 2.944 | 2.048 | 18.944 | 2/5 (40%) |
| Divis√£o | 7.408 | 1.064 | 930.638 | 0/5 (0%) |

### An√°lise de Casos Espec√≠ficos
Exemplos representativos do conjunto de teste:

**Adi√ß√£o (bom desempenho):**
```
-3.58 + -5.19 = -8.7784 (Predito: -8.9009, Erro: 0.1225)
```

**Subtra√ß√£o (desempenho vari√°vel):**
```
-9.90 - 9.67 = -19.5680 (Predito: -26.3897, Erro: 6.8216)
```

**Multiplica√ß√£o (desafios em valores maiores):**
```
-9.00 * -6.32 = 56.8851 (Predito: 54.2390, Erro: 2.6461)
```

**Divis√£o (problemas significativos):**
```
-2.11 / -0.89 = 2.3601 (Predito: 0.0550, Erro: 2.3051)
```

### An√°lise de Overfitting/Underfitting
- N√£o observamos overfitting significativo gra√ßas √†s t√©cnicas de regulariza√ß√£o
- A diverg√™ncia entre erros por opera√ß√£o sugere que um √∫nico modelo pode n√£o ser ideal para todas as opera√ß√µes

## üîç Conclus√µes e Recomenda√ß√µes

### Principais Insights
1. Hierarquia clara de dificuldade: Adi√ß√£o < Subtra√ß√£o < Multiplica√ß√£o < Divis√£o
2. A estrutura "ampulheta" (128‚Üí32‚Üí128) mostrou-se eficiente para capturar padr√µes matem√°ticos
3. A combina√ß√£o ReLU + SELU superou configura√ß√µes homog√™neas de ativa√ß√£o

### Melhorias Propostas
1. **Modelos Especializados:** Treinar redes separadas para cada opera√ß√£o
2. **Pr√©-processamento Adaptativo:** Diferentes estrat√©gias de normaliza√ß√£o por opera√ß√£o
3. **Dataset Expandido:** Maior cobertura de casos extremos, especialmente para divis√£o
4. **Arquiteturas Alternativas:** Explorar redes mais profundas para opera√ß√µes complexas

## üöÄ Como Executar

```bash
# Instala√ß√£o das depend√™ncias
pip install tensorflow numpy matplotlib sklearn keras-tuner

# Executar o c√≥digo principal
python final.py
```

## üìö Refer√™ncias

- Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press.
- TensorFlow Documentation: https://www.tensorflow.org/
- Keras Tuner: https://keras.io/keras_tuner/
- Chollet, F. (2021). Deep Learning with Python. Manning Publications.